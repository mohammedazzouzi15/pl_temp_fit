2025-03-13 09:39:44.074293: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-03-13 09:39:44.093458: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-03-13 09:39:44.093484: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-03-13 09:39:44.094139: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-03-13 09:39:44.097485: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-03-13 09:39:44.422905: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
INFO:root:Performing 2 pilot runs with the PL spectra simulator model...
INFO:root:Shape of parameter batch after 2 pilot simulations: (batch_size = 2, 5)
INFO:root:Shape of simulation batch after 2 pilot simulations: (batch_size = 2, 67, 3)
INFO:root:No optional prior non-batchable context provided.
INFO:root:No optional prior batchable context provided.
INFO:root:No optional simulation non-batchable context provided.
INFO:root:No optional simulation batchable context provided.
2025-03-13 09:39:46.530210: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-03-13 09:39:46.551054: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-03-13 09:39:46.551174: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-03-13 09:39:46.552178: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-03-13 09:39:46.552252: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-03-13 09:39:46.552294: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-03-13 09:39:46.591505: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-03-13 09:39:46.591604: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-03-13 09:39:46.591662: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-03-13 09:39:46.591705: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 809 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9
INFO:root:Loaded loss history from checkpoints.ckpt/history_30.pkl.
INFO:root:Loaded simulation memory from checkpoints.ckpt/memory.pkl
INFO:root:Networks loaded from checkpoints.ckpt/ckpt-30
INFO:root:Performing a consistency check with provided components...
2025-03-13 09:39:46.925510: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904
2025-03-13 09:39:46.959294: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory
2025-03-13 09:39:47.066787: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory
2025-03-13 09:39:47.123463: W tensorflow/core/framework/op_kernel.cc:1827] INVALID_ARGUMENT: required broadcastable shapes
Prior means: [[1.70316747 0.05076408 0.11640371 0.11266386 0.14874606]]
Prior stds: [[0.11873291 0.02857572 0.04961553 0.04940846 0.02887037]]
Traceback (most recent call last):
  File "/media/mohammed/Work/anaconda3/envs/pl_temp_fit/lib/python3.11/site-packages/bayesflow/trainers.py", line 1315, in _check_consistency
    _ = self.amortizer.compute_loss(self.configurator(self.generative_model(_n_sim)))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/mohammed/Work/anaconda3/envs/pl_temp_fit/lib/python3.11/site-packages/bayesflow/amortizers.py", line 208, in compute_loss
    net_out, sum_out = self(input_dict, return_summary=True, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/mohammed/Work/anaconda3/envs/pl_temp_fit/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/media/mohammed/Work/anaconda3/envs/pl_temp_fit/lib/python3.11/site-packages/bayesflow/amortizers.py", line 173, in call
    summary_out, full_cond = self._compute_summary_condition(
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/mohammed/Work/anaconda3/envs/pl_temp_fit/lib/python3.11/site-packages/bayesflow/amortizers.py", line 403, in _compute_summary_condition
    sum_condition = self.summary_net(summary_conditions, **kwargs)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/mohammed/Work/pl_temp_fit/src/pl_temp_fit/bayesflow/train_bayesflow.py", line 141, in call
    x += residual
tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling layer 'custom_res_net' (type CustomResNet).

{{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} required broadcastable shapes [Op:AddV2] name: 

Call arguments received by layer 'custom_res_net' (type CustomResNet):
  • x=tf.Tensor(shape=(2, 67, 3), dtype=float32)
  • kwargs={'training': 'None'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/media/mohammed/Work/pl_temp_fit/src/pl_temp_fit/bayesflow/train_bayesflow.py", line 163, in <module>
    trainer = Trainer(
              ^^^^^^^^
  File "/media/mohammed/Work/anaconda3/envs/pl_temp_fit/lib/python3.11/site-packages/bayesflow/trainers.py", line 220, in __init__
    self._check_consistency()
  File "/media/mohammed/Work/anaconda3/envs/pl_temp_fit/lib/python3.11/site-packages/bayesflow/trainers.py", line 1318, in _check_consistency
    raise ConfigurationError(
bayesflow.exceptions.ConfigurationError: Could not carry out computations of generative_model ->configurator -> amortizer -> loss! Error trace:
 Exception encountered when calling layer 'custom_res_net' (type CustomResNet).

{{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} required broadcastable shapes [Op:AddV2] name: 

Call arguments received by layer 'custom_res_net' (type CustomResNet):
  • x=tf.Tensor(shape=(2, 67, 3), dtype=float32)
  • kwargs={'training': 'None'}
Exception ignored in: <function _CheckpointRestoreCoordinatorDeleter.__del__ at 0x7dbbe01fb1a0>
Traceback (most recent call last):
  File "/media/mohammed/Work/anaconda3/envs/pl_temp_fit/lib/python3.11/site-packages/tensorflow/python/checkpoint/checkpoint.py", line 214, in __del__
TypeError: 'NoneType' object is not callable
2025-03-13 09:39:56.677530: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-03-13 09:39:56.697338: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-03-13 09:39:56.697363: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-03-13 09:39:56.698039: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-03-13 09:39:56.701510: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-03-13 09:39:57.033035: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
INFO:root:Performing 2 pilot runs with the PL spectra simulator model...
INFO:root:Shape of parameter batch after 2 pilot simulations: (batch_size = 2, 5)
INFO:root:Shape of simulation batch after 2 pilot simulations: (batch_size = 2, 67, 3)
INFO:root:No optional prior non-batchable context provided.
INFO:root:No optional prior batchable context provided.
INFO:root:No optional simulation non-batchable context provided.
INFO:root:No optional simulation batchable context provided.
2025-03-13 09:39:59.122472: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-03-13 09:39:59.141051: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-03-13 09:39:59.141164: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-03-13 09:39:59.142549: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-03-13 09:39:59.142618: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-03-13 09:39:59.142661: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-03-13 09:39:59.186970: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-03-13 09:39:59.187055: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-03-13 09:39:59.187109: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-03-13 09:39:59.187154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 841 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9
INFO:root:Initialized empty loss history.
INFO:root:Initialized empty simulation memory.
INFO:root:Initialized networks from scratch.
INFO:root:Performing a consistency check with provided components...
2025-03-13 09:39:59.492450: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904
2025-03-13 09:39:59.526357: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory
2025-03-13 09:39:59.647087: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory
2025-03-13 09:39:59.706183: W tensorflow/core/framework/op_kernel.cc:1827] INVALID_ARGUMENT: required broadcastable shapes
Prior means: [[1.69911629 0.05159898 0.11729335 0.11599841 0.15019058]]
Prior stds: [[0.11623482 0.02831834 0.04992673 0.04900219 0.02863716]]
Traceback (most recent call last):
  File "/media/mohammed/Work/anaconda3/envs/pl_temp_fit/lib/python3.11/site-packages/bayesflow/trainers.py", line 1315, in _check_consistency
    _ = self.amortizer.compute_loss(self.configurator(self.generative_model(_n_sim)))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/mohammed/Work/anaconda3/envs/pl_temp_fit/lib/python3.11/site-packages/bayesflow/amortizers.py", line 208, in compute_loss
    net_out, sum_out = self(input_dict, return_summary=True, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/mohammed/Work/anaconda3/envs/pl_temp_fit/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/media/mohammed/Work/anaconda3/envs/pl_temp_fit/lib/python3.11/site-packages/bayesflow/amortizers.py", line 173, in call
    summary_out, full_cond = self._compute_summary_condition(
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/mohammed/Work/anaconda3/envs/pl_temp_fit/lib/python3.11/site-packages/bayesflow/amortizers.py", line 403, in _compute_summary_condition
    sum_condition = self.summary_net(summary_conditions, **kwargs)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/mohammed/Work/pl_temp_fit/src/pl_temp_fit/bayesflow/train_bayesflow.py", line 141, in call
    x += residual
tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling layer 'custom_res_net' (type CustomResNet).

{{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} required broadcastable shapes [Op:AddV2] name: 

Call arguments received by layer 'custom_res_net' (type CustomResNet):
  • x=tf.Tensor(shape=(2, 67, 3), dtype=float32)
  • kwargs={'training': 'None'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/media/mohammed/Work/pl_temp_fit/src/pl_temp_fit/bayesflow/train_bayesflow.py", line 163, in <module>
    trainer = Trainer(
              ^^^^^^^^
  File "/media/mohammed/Work/anaconda3/envs/pl_temp_fit/lib/python3.11/site-packages/bayesflow/trainers.py", line 220, in __init__
    self._check_consistency()
  File "/media/mohammed/Work/anaconda3/envs/pl_temp_fit/lib/python3.11/site-packages/bayesflow/trainers.py", line 1318, in _check_consistency
    raise ConfigurationError(
bayesflow.exceptions.ConfigurationError: Could not carry out computations of generative_model ->configurator -> amortizer -> loss! Error trace:
 Exception encountered when calling layer 'custom_res_net' (type CustomResNet).

{{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} required broadcastable shapes [Op:AddV2] name: 

Call arguments received by layer 'custom_res_net' (type CustomResNet):
  • x=tf.Tensor(shape=(2, 67, 3), dtype=float32)
  • kwargs={'training': 'None'}
2025-03-13 09:48:42.290365: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-03-13 09:48:42.309769: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-03-13 09:48:42.309799: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-03-13 09:48:42.310461: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-03-13 09:48:42.313896: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-03-13 09:48:42.639963: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
INFO:root:Performing 2 pilot runs with the PL spectra simulator model...
INFO:root:Shape of parameter batch after 2 pilot simulations: (batch_size = 2, 5)
INFO:root:Shape of simulation batch after 2 pilot simulations: (batch_size = 2, 67, 3)
INFO:root:No optional prior non-batchable context provided.
INFO:root:No optional prior batchable context provided.
INFO:root:No optional simulation non-batchable context provided.
INFO:root:No optional simulation batchable context provided.
2025-03-13 09:48:44.723807: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-03-13 09:48:44.742263: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-03-13 09:48:44.742371: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-03-13 09:48:44.743612: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-03-13 09:48:44.743681: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-03-13 09:48:44.743722: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-03-13 09:48:44.782212: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-03-13 09:48:44.782308: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-03-13 09:48:44.782359: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-03-13 09:48:44.782401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 841 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9
INFO:root:Initialized empty loss history.
INFO:root:Initialized empty simulation memory.
INFO:root:Initialized networks from scratch.
INFO:root:Performing a consistency check with provided components...
2025-03-13 09:48:45.092920: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904
2025-03-13 09:48:45.126404: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory
2025-03-13 09:48:45.242317: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory
INFO:root:Done.
Prior means: [[1.70212915 0.05146023 0.11436339 0.11333404 0.15115414]]
Prior stds: [[0.1153059  0.02876753 0.04865999 0.04941052 0.02930769]]
Model: "PL_spectra_amortizer"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 invertible_network (Invert  multiple                  427670    
 ibleNetwork)                                                    
                                                                 
 custom_res_net (CustomResN  multiple                  103968    
 et)                                                             
                                                                 
=================================================================
Total params: 531638 (2.03 MB)
Trainable params: 531588 (2.03 MB)
Non-trainable params: 50 (200.00 Byte)
_________________________________________________________________
None
Training epoch 1:   0%|          | 0/500 [00:00<?, ?it/s]2025-03-13 09:48:51.403553: I external/local_xla/xla/service/service.cc:168] XLA service 0x7c96b3de4590 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-03-13 09:48:51.403577: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9
2025-03-13 09:48:51.405845: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1741855731.454092 2605450 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Training epoch 1:   0%|          | 1/500 [00:09<1:17:27,  9.31s/it, Epoch: 1, Iter: 1,Loss: 6.122,Avg.Loss: 6.122,LR: 5.00E-04]Training epoch 1:   0%|          | 2/500 [00:10<39:14,  4.73s/it, Epoch: 1, Iter: 2,Loss: nan,Avg.Loss: nan,LR: 5.00E-04]      Training epoch 1:   1%|          | 3/500 [00:12<26:59,  3.26s/it, Epoch: 1, Iter: 3,Loss: nan,Avg.Loss: nan,LR: 5.00E-04]Training epoch 1:   1%|          | 4/500 [00:13<21:11,  2.56s/it, Epoch: 1, Iter: 4,Loss: nan,Avg.Loss: nan,LR: 5.00E-04]Training epoch 1:   1%|          | 5/500 [00:15<18:02,  2.19s/it, Epoch: 1, Iter: 5,Loss: nan,Avg.Loss: nan,LR: 5.00E-04]Training epoch 1:   1%|          | 6/500 [00:16<16:17,  1.98s/it, Epoch: 1, Iter: 6,Loss: nan,Avg.Loss: nan,LR: 5.00E-04]Training epoch 1:   1%|▏         | 7/500 [00:18<15:02,  1.83s/it, Epoch: 1, Iter: 7,Loss: nan,Avg.Loss: nan,LR: 5.00E-04]Training epoch 1:   2%|▏         | 8/500 [00:19<14:10,  1.73s/it, Epoch: 1, Iter: 8,Loss: nan,Avg.Loss: nan,LR: 5.00E-04]Training epoch 1:   2%|▏         | 9/500 [00:21<13:36,  1.66s/it, Epoch: 1, Iter: 9,Loss: nan,Avg.Loss: nan,LR: 5.00E-04]Training epoch 1:   2%|▏         | 10/500 [00:22<13:12,  1.62s/it, Epoch: 1, Iter: 10,Loss: nan,Avg.Loss: nan,LR: 5.00E-04]Training epoch 1:   2%|▏         | 11/500 [00:24<13:16,  1.63s/it, Epoch: 1, Iter: 11,Loss: nan,Avg.Loss: nan,LR: 5.00E-04]Training epoch 1:   2%|▏         | 12/500 [00:26<13:01,  1.60s/it, Epoch: 1, Iter: 12,Loss: nan,Avg.Loss: nan,LR: 5.00E-04]Training epoch 1:   3%|▎         | 13/500 [00:27<12:51,  1.59s/it, Epoch: 1, Iter: 13,Loss: nan,Avg.Loss: nan,LR: 5.00E-04]Training epoch 1:   3%|▎         | 14/500 [00:29<12:44,  1.57s/it, Epoch: 1, Iter: 14,Loss: nan,Avg.Loss: nan,LR: 5.00E-04]Training epoch 1:   3%|▎         | 15/500 [00:30<12:42,  1.57s/it, Epoch: 1, Iter: 15,Loss: nan,Avg.Loss: nan,LR: 5.00E-04]Training epoch 1:   3%|▎         | 16/500 [00:32<12:34,  1.56s/it, Epoch: 1, Iter: 16,Loss: nan,Avg.Loss: nan,LR: 5.00E-04]Training epoch 1:   3%|▎         | 17/500 [00:33<12:28,  1.55s/it, Epoch: 1, Iter: 17,Loss: nan,Avg.Loss: nan,LR: 5.00E-04]Training epoch 1:   4%|▎         | 18/500 [00:35<12:26,  1.55s/it, Epoch: 1, Iter: 18,Loss: nan,Avg.Loss: nan,LR: 5.00E-04]Training epoch 1:   4%|▍         | 19/500 [00:36<12:20,  1.54s/it, Epoch: 1, Iter: 19,Loss: nan,Avg.Loss: nan,LR: 5.00E-04]Training epoch 1:   4%|▍         | 20/500 [00:38<12:21,  1.55s/it, Epoch: 1, Iter: 20,Loss: nan,Avg.Loss: nan,LR: 5.00E-04]Training epoch 1:   4%|▍         | 21/500 [00:40<12:17,  1.54s/it, Epoch: 1, Iter: 21,Loss: nan,Avg.Loss: nan,LR: 5.00E-04]